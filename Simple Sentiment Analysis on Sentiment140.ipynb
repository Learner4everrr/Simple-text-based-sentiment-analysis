{"cells":[{"cell_type":"markdown","id":"exterior-subject","metadata":{"id":"exterior-subject"},"source":["**Install necessary packages and downgrade torchtext**"]},{"cell_type":"code","execution_count":null,"id":"consecutive-stable","metadata":{"id":"consecutive-stable"},"outputs":[],"source":["!pip install torchtext==0.6.0\n","!pip install spacy"]},{"cell_type":"code","execution_count":null,"id":"athletic-zimbabwe","metadata":{"id":"athletic-zimbabwe"},"outputs":[],"source":["#!pip install numpy==1.21.0\n","#!pip install pandas\n","!python -m spacy download en_core_web_sm"]},{"cell_type":"markdown","id":"55d25c99","metadata":{"id":"55d25c99"},"source":["**Load the dataset + Split dataset + Data Cleaning**"]},{"cell_type":"code","execution_count":null,"id":"specialized-glucose","metadata":{"id":"specialized-glucose"},"outputs":[],"source":["import pandas as pd\n","base_csv = './training.1600000.processed.noemoticon.csv'\n","df = pd.read_csv(base_csv,encoding='ISO-8859-1',header=None)\n","df.columns = ['sentiment','id','date','flag','user','tweet']\n","df.head()\n","\n","df = df[['sentiment', 'tweet']]\n","\n","import re\n","\n","def clean_text(text):\n","    if isinstance(text, str):  # Check if it's a string\n","        text = text.lower() # lowercase\n","        text = text.replace(r\"\\#\",\"\") # replaces hashtags\n","        text = text.replace(\"\\s{2,}\", \" \")\n","        text = re.sub(r'http\\S+', '', text)  # Remove URLs\n","        text = re.sub(r'@[^\\s]+', '', text)  # Remove Twitter handles\n","        text = text.replace(r\"[^A-Za-z0-9()!?\\'\\`\\\"]\", \" \")\n","        return text\n","    else:\n","        return ''\n","\n","df['tweet'] = df['tweet'].apply(clean_text)\n","df.head()\n","# Specify the file path where you want to save the CSV file\n","csv_file_path = 'data.csv'\n","\n","# Save the DataFrame to a CSV file with headers\n","df.to_csv(csv_file_path, index=False)"]},{"cell_type":"code","execution_count":null,"id":"discrete-example","metadata":{"scrolled":true,"id":"discrete-example","outputId":"a6151fef-a34a-4a1b-9d1b-d815e9720900"},"outputs":[{"name":"stdout","output_type":"stream","text":["[<torchtext.data.example.Example object at 0x0000012728DF2A50>, <torchtext.data.example.Example object at 0x000001270A181CD0>, <torchtext.data.example.Example object at 0x000001270FFC9C90>, <torchtext.data.example.Example object at 0x000001272C588550>, <torchtext.data.example.Example object at 0x000001272C58BC90>, <torchtext.data.example.Example object at 0x000001272C58BDD0>, <torchtext.data.example.Example object at 0x000001272C588450>, <torchtext.data.example.Example object at 0x0000012709104290>, <torchtext.data.example.Example object at 0x0000012709104150>, <torchtext.data.example.Example object at 0x000001272C58B750>]\n"]}],"source":["import spacy\n","spacy.load('en_core_web_sm')\n","import torch\n","import torchtext.data as data\n","\n","SEED = 1234\n","\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","TEXT = data.Field(tokenize = 'spacy',\n","                  tokenizer_language = 'en_core_web_sm',\n","                  include_lengths = True)\n","\n","LABEL = data.LabelField(dtype = torch.float)\n","\n","# Create fields mapping to your DataFrame columns\n","fields = [('sentiment', LABEL), ('tweet', TEXT)]\n","\n","# Load the DataFrame into a torchtext TabularDataset\n","all_data = data.TabularDataset(\n","    path='data.csv',\n","    format='csv',\n","    fields={'sentiment': ('label', LABEL), 'tweet': ('text', TEXT)},\n","    skip_header=False\n",")\n","print(all_data[:10])"]},{"cell_type":"code","execution_count":null,"id":"copyrighted-import","metadata":{"id":"copyrighted-import","outputId":"e55614b2-42e6-4afb-ea22-988a863f19d6"},"outputs":[{"name":"stderr","output_type":"stream","text":[".vector_cache\\glove.6B.zip: 862MB [02:43, 5.28MB/s]                                                  \n","100%|████████████████████████████████████████████████████▉| 399999/400000 [00:24<00:00, 16381.68it/s]\n"]}],"source":["MAX_VOCAB_SIZE = 25_000\n","\n","TEXT.build_vocab(all_data,\n","                 max_size = MAX_VOCAB_SIZE,\n","                 vectors = \"glove.6B.100d\",\n","                 unk_init = torch.Tensor.normal_)\n","\n","LABEL.build_vocab(all_data)"]},{"cell_type":"code","execution_count":null,"id":"incorporate-person","metadata":{"id":"incorporate-person","outputId":"2886b0ea-29eb-4be1-dc42-8fdc9a86eb5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["import spacy\n","import random\n","nlp = spacy.load(\"en_core_web_sm\")\n","# Split the data into training (60%), validation (20%), and test (20%)\n","train_data, valid_data, test_data = all_data.split(split_ratio=[0.6, 0.2, 0.2], random_state=random.seed(42))\n","\n","# Create iterators\n","BATCH_SIZE = 256\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size=BATCH_SIZE,\n","    sort_within_batch=True,\n","    sort_key=lambda x: len(x.text),\n","    device=device\n",")"]},{"cell_type":"markdown","id":"231b3bfb","metadata":{"id":"231b3bfb"},"source":["**C)Model using Bi-LSTM**"]},{"cell_type":"code","execution_count":null,"id":"portuguese-macedonia","metadata":{"id":"portuguese-macedonia"},"outputs":[],"source":["import torch.nn as nn\n","\n","class ImprovedRNN(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n","        super().__init__()\n","        self.embedding = nn.Embedding(input_dim, embedding_dim)\n","        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n","        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, text, text_lengths):\n","        embedded = self.dropout(self.embedding(text))\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n","        output, (hidden, _) = self.rnn(packed_embedded)\n","        if self.rnn.bidirectional:\n","            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n","        else:\n","            hidden = self.dropout(hidden[-1,:,:])\n","        return self.fc(hidden)"]},{"cell_type":"code","execution_count":null,"id":"broke-words","metadata":{"id":"broke-words","outputId":"e51c9459-0a23-4c63-d2f8-6bcfd4b42a80"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\91338\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"name":"stdout","output_type":"stream","text":["The model has 3,233,897 trainable parameters\n","torch.Size([25002, 100])\n","tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n","        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n","        [ 0.4298,  0.8205, -1.4562,  ...,  1.4802,  0.2942,  1.3924],\n","        ...,\n","        [-0.3882, -0.1119, -1.0825,  ...,  0.0722, -0.3288,  2.0514],\n","        [-1.6867,  0.4126, -1.3478,  ..., -0.1019, -0.2058, -1.6541],\n","        [-0.5421,  0.2786,  0.4252,  ...,  0.4125, -0.0876, -0.2877]])\n"]}],"source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 1\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","# model\n","model = ImprovedRNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)\n","model.to()\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')\n","\n","pretrained_embeddings = TEXT.vocab.vectors\n","\n","print(pretrained_embeddings.shape)\n","\n","model.embedding.weight.data.copy_(pretrained_embeddings)\n","\n","#UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","\n","#model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","#model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","print(model.embedding.weight.data)"]},{"cell_type":"code","execution_count":null,"id":"sacred-language","metadata":{"id":"sacred-language"},"outputs":[],"source":["import torch.optim as optim\n","\n","def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division\n","    acc = correct.sum() / len(correct)\n","    return acc\n","\n","def train(model, iterator, optimizer, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","\n","    for batch in iterator:\n","\n","        optimizer.zero_grad()\n","        #print(batch)\n","        text, text_lengths = batch.text\n","\n","        predictions = model(text, text_lengths).squeeze(1)\n","\n","        loss = criterion(predictions, batch.label)\n","\n","        acc = binary_accuracy(predictions, batch.label)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        #print('--')\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","\n","\n","def evaluate(model, iterator, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for batch in iterator:\n","\n","            text, text_lengths = batch.text\n","\n","            predictions = model(text, text_lengths).squeeze(1)\n","\n","            loss = criterion(predictions, batch.label)\n","\n","            acc = binary_accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","\n","\n","import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"markdown","id":"d73e516e","metadata":{"id":"d73e516e"},"source":["**Trainning**"]},{"cell_type":"code","execution_count":null,"id":"lined-renaissance","metadata":{"id":"lined-renaissance","outputId":"a39e7170-7094-4891-88f2-f82544ac6bf4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 01 | Epoch Time: 1m 2s\n","\tTrain Loss: 0.370 | Train Acc: 83.56%\n","\t Val. Loss: 0.345 |  Val. Acc: 84.88%\n","Epoch: 02 | Epoch Time: 1m 2s\n","\tTrain Loss: 0.349 | Train Acc: 84.67%\n","\t Val. Loss: 0.339 |  Val. Acc: 85.26%\n"]}],"source":["optimizer = optim.Adam(model.parameters())\n","criterion = nn.BCEWithLogitsLoss()\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","\n","epoch = 1\n","test_acc = 0\n","best_valid_loss = float('inf')\n","\n","while test_acc < 0.85:\n","\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    test_loss, test_acc = evaluate(model, valid_iterator, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'birnnmodel.pt')\n","\n","    print(f'Epoch: {epoch:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n","\n","    epoch = epoch + 1"]},{"cell_type":"markdown","id":"20d652f5","metadata":{"id":"20d652f5"},"source":["**d) 85% in test set**"]},{"cell_type":"code","execution_count":null,"id":"known-spencer","metadata":{"id":"known-spencer","outputId":"db41a7ef-34aa-4cd4-80bf-5cb6ce488b95"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Loss: 0.340 | Test Acc: 85.31%\n"]}],"source":["model.load_state_dict(torch.load('birnnmodel.pt'))\n","\n","test_loss, test_acc = evaluate(model, test_iterator, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}